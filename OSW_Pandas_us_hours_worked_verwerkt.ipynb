{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnijhuis-dnb/open_source_workshop/blob/master/OSW_Pandas_us_hours_worked_verwerkt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU0KM0cD1po9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ergY4Tzdz5eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_files(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz2BJezE1h4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_NAICS = '/NAICS.json'\n",
        "file_Global_mobility_report = '/Global_mobility_report.csv'\n",
        "file_US_Hours_Worked = '/US_Hours_Worked.json'\n",
        "file_PPP_Loan_data = '/PPP_Loan_data.csv'\n",
        "file_US_zips = '/uszips.xslx'\n",
        "\n",
        "download_files('1Fe73x8Splw9xY5FOTnpLWENJaBU2tHEy', file_NAICS)\n",
        "download_files('1d4C6sTuD53tc_Ewbfb1iXascKzDSzDl0', file_Global_mobility_report)\n",
        "download_files('1KzT1XNA9K0enUv73nwPSkBYp7btg0pvJ', file_US_Hours_Worked)\n",
        "download_files('1_7s1tH7FVNA5s5gu1vcWxikmGYQ2ryvn', file_PPP_Loan_data)\n",
        "download_files('1f-ru7e4Ml0d5uzOMGtNpmOQ3kGSr7iT_', file_US_zips)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpD67u6FwuWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Hours_Worked = pd.read_json(file_US_Hours_Worked)\n",
        "df_Hours_Worked = pd.merge(df_Hours_Worked, \n",
        "              pd.DataFrame(\n",
        "                  [list(row.values()) for row in df_Hours_Worked['Results']]\n",
        "                  ,columns=list(df_Hours_Worked['Results'][1]))\n",
        "              ,left_index=True,right_index=True).drop(columns=['Results'])\n",
        "              \n",
        "df_Hours_Worked = pd.merge(df_Hours_Worked, \n",
        "              pd.DataFrame(\n",
        "                  [[dicts['value'] for dicts in row] for row in df_Hours_Worked['data']]\n",
        "                 ,columns=[dicts['year'] + dicts['period'] for dicts in df_Hours_Worked['data'][77]])\n",
        "              ,left_index=True,right_index=True).drop(columns=['data'])\n",
        "df_Hours_Worked['NAICS'] = pd.to_numeric(df_Hours_Worked['NAICS'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}