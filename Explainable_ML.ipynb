{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explainable ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au5kt-MWxS9c"
      },
      "source": [
        "#Data loading\r\n",
        "\r\n",
        "In practise we will use the US census income dataset: \r\n",
        "https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29\r\n",
        "\r\n",
        "We will start with the installation of the packages we arre going to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Zj8yZTDMyP"
      },
      "source": [
        "!pip install shap\r\n",
        "!pip install eli5\r\n",
        "!pip install pdpbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_3omjbAJ303"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import shap\r\n",
        "import xgboost as xgb\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIujChx5G142"
      },
      "source": [
        "Downloading and installing the data which will be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJbgZuqfHDXt"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.data.gz\r\n",
        "!gunzip census-income.data.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDNbsKK3enTq"
      },
      "source": [
        "Reading in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxbVTcnnI2bP"
      },
      "source": [
        "dtypes = [\r\n",
        "\t('age', 'float32'), ('class of worker', 'category'), ('detailed industry recode', 'category'), \r\n",
        "\t('detailed occupation recode', 'category'), ('education', 'category'), ('wage per hour', 'float32'), \r\n",
        "\t('enroll in edu inst last wk', 'category'), ('marital stat', 'category'), ('major industry code', 'category'), \r\n",
        "\t('major occupation code', 'category'), ('race', 'category'), ('hispanic origin', 'category'), \r\n",
        "\t('sex', 'category'), ('member of a labor union', 'category'), ('reason for unemployment', 'category'), \r\n",
        "\t('full or part time employment stat', 'category'), ('capital gains', 'float32'), \r\n",
        "\t('capital losses', 'float32'), ('dividends from stocks', 'float32'), ('tax filer stat', 'category'), \r\n",
        "\t('region of previous residence', 'category'), ('state of previous residence', 'category'), \r\n",
        "\t('detailed household and family stat', 'category'), ('detailed household summary in household', 'category'), \r\n",
        "\t('instance weight_ignore', 'float32'), ('migration code-change in msa', 'category'), \r\n",
        "\t('migration code-change in reg', 'category'), ('migration code-move within reg', 'category'), \r\n",
        "\t('live in this house 1 year ago', 'category'), ('migration prev res in sunbelt', 'category'), \r\n",
        "\t('num persons worked for employer', 'float32'),\t('family members under 18', 'category'), \r\n",
        "\t('country of birth father', 'category'), ('country of birth mother', 'category'), \r\n",
        "\t('country of birth self', 'category'), ('citizenship', 'category'), ('own business or self employed', 'category'), \r\n",
        "\t('fill inc questionnaire for veteran\\'s admin', 'category'), ('veterans benefits', 'category'), \r\n",
        "\t('weeks worked in year', 'float32'), ('year', 'category'), ('targets', 'category')]\r\n",
        "\r\n",
        "raw_data = pd.read_csv('census-income.data', names=[d[0] for d in dtypes], dtype=dict(dtypes))\r\n",
        "\r\n",
        "edu_code = {\"Children\": 0,\r\n",
        "            \"Less than 1st grade\": 1,  \r\n",
        "            \"1st 2nd 3rd or 4th grade\": 2,  \r\n",
        "            \"5th or 6th grade\": 3, \r\n",
        "            \"7th and 8th grade\": 4, \r\n",
        "            \"9th grade\": 5, \r\n",
        "            \"10th grade\": 6, \r\n",
        "            \"11th grade\": 7, \r\n",
        "            \"12th grade no diploma\": 8, \r\n",
        "            \"High school graduate\": 9,\r\n",
        "            \"Some college but no degree\": 10,\r\n",
        "            \"Associates degree-academic program\": 11, \r\n",
        "            \"Associates degree-occup /vocational\": 12,\r\n",
        "            \"Bachelors degree(BA AB BS)\": 13,\r\n",
        "            \"Masters degree(MA MS MEng MEd MSW MBA)\": 14,  \r\n",
        "            \"Prof school degree (MD DDS DVM LLB JD)\": 15,\r\n",
        "            \"Doctorate degree(PhD EdD)\": 15}\r\n",
        "raw_data['education-num'] = np.array([edu_code[v.strip()] for v in raw_data['education']]).astype('float32')\r\n",
        "dtypes.append(('education-num','float32'))\r\n",
        "\r\n",
        "targets, target_value = pd.factorize(raw_data['targets'])\r\n",
        "raw_data = raw_data.drop(columns=['instance weight_ignore', 'targets'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmecZtx6J9PK"
      },
      "source": [
        "Some data cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaJpQwC6Dm-O"
      },
      "source": [
        "# remove some of the data to make it calculate quicker\r\n",
        "data = raw_data.drop(columns=['detailed industry recode', 'detailed occupation recode', \r\n",
        "                              'major industry code', 'major occupation code', 'education', \r\n",
        "                              'country of birth father',  'country of birth mother', \r\n",
        "                              'country of birth self', 'state of previous residence', \r\n",
        "                              'detailed household and family stat'])\r\n",
        "data_for_plot = data.copy()\r\n",
        "binary_columns = ['sex','member of a labor union','live in this house 1 year ago',\r\n",
        "                   'migration prev res in sunbelt','own business or self employed',\r\n",
        "                   'fill inc questionnaire for veteran\\'s admin','veterans benefits',\r\n",
        "                   'year']\r\n",
        "\r\n",
        "binary_data = data[binary_columns].copy()\r\n",
        "categorical_data = data.select_dtypes(include=['category']).drop(columns=binary_data)\r\n",
        "numerical_data = data.select_dtypes(include=['float32'])\r\n",
        "\r\n",
        "binary_data[(binary_data==' 2') | (binary_data==' ?') | (binary_data==' Not in universe') | (binary_data==' Not in universe under 1 year old')] = np.nan\r\n",
        "binary_data = (binary_data.apply(lambda x: pd.factorize(x)[0]))\r\n",
        "\r\n",
        "# encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\r\n",
        "# encoder.fit(categorical_data)\r\n",
        "\r\n",
        "# data = pd.DataFrame(np.hstack((encoder.transform(categorical_data),numerical_data.values, binary_data.values)),\r\n",
        "#                     columns=[categorical_data.columns[idx] + '_' + item for idx, sublist in enumerate([array.tolist() for array in encoder.categories_]) for item in sublist]\r\n",
        "#                     + list(numerical_data.columns) + list(binary_data.columns))\r\n",
        "\r\n",
        "categorical_data = categorical_data.apply(lambda x : pd.factorize(x)[0])\r\n",
        "data = pd.DataFrame(np.hstack((categorical_data,numerical_data.values, binary_data.values)),\r\n",
        "                     columns=list(categorical_data.columns) + list(numerical_data.columns) + list(binary_data.columns))\r\n",
        "data = data.reindex(columns=data_for_plot.columns)\r\n",
        "\r\n",
        "train_x, val_x, train_y, val_y = train_test_split(data, pd.Series(targets), random_state=99)\r\n",
        "\r\n",
        "index = np.random.permutation(np.hstack((train_y.index.values[train_y==1],np.random.permutation(train_y.index.values[train_y==0])))[:2*np.sum(train_y==1)])\r\n",
        "train_x_new = train_x.loc[index]\r\n",
        "train_y_new = train_y.loc[index]\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrE035fHJ_l1"
      },
      "source": [
        "Building a model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAzAtAR_Dfbd"
      },
      "source": [
        "my_model = RandomForestClassifier(random_state=99, min_samples_split=500, max_leaf_nodes=50, oob_score=True).fit(train_x_new, train_y_new)\r\n",
        "print(f'Model accuracy: {np.round(np.sum(my_model.predict(val_x)==val_y)/len(val_y)*100,1)}%')\r\n",
        "print(f'Model recall: {np.round(np.sum((my_model.predict(val_x)==1) & (val_y==1))/np.sum(val_y==1)*100,1)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR4MSs3CxV4E"
      },
      "source": [
        "#ELI5\r\n",
        "Calculating featur importance with eli5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPAlf0r7xWVk"
      },
      "source": [
        "import eli5\r\n",
        "from eli5.sklearn import PermutationImportance\r\n",
        "\r\n",
        "perm = PermutationImportance(my_model, random_state=1, scoring='recall').fit(val_x, val_y)\r\n",
        "eli5.show_weights(perm, feature_names = data.columns.to_list(), top=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7M5ZwFqBWp2"
      },
      "source": [
        "#partial dependence plots\r\n",
        "Now we will create a couple of partial dependence plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9McMxbBazn"
      },
      "source": [
        "feature_to_plot = 'tax filer stat'\r\n",
        "pdp_hours = pdp.pdp_isolate(model=my_model, dataset=val_x, model_features=data.columns.to_list(), cust_grid_points=np.r_[0:6], feature=feature_to_plot)\r\n",
        "\r\n",
        "pdp.pdp_plot(pdp_hours, feature_to_plot)\r\n",
        "plt.show()\r\n",
        "pd.factorize(raw_data['tax filer stat'])[1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbx1QdI_BX_O"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "from pdpbox import pdp, get_dataset, info_plots\r\n",
        "\r\n",
        "pdp_education = pdp.pdp_isolate(model=my_model, dataset=val_x, model_features=data.columns.to_list(), cust_grid_points=np.r_[0:16], feature='education-num')\r\n",
        "\r\n",
        "# plot it\r\n",
        "pdp.pdp_plot(pdp_education, 'education-num')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd5_qB0NBhUO"
      },
      "source": [
        "Also works with contour plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-B9IVlzBi0m"
      },
      "source": [
        "features_to_plot = ['age', 'education-num']\r\n",
        "inter1  =  pdp.pdp_interact(model=my_model, dataset=val_x, model_features=data.columns.to_list(), features=features_to_plot)\r\n",
        "pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9SCLca3B-l3"
      },
      "source": [
        "#SHAP\r\n",
        "Now we will take a look at the Shapley values for a single row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9PgEWwcCBGu"
      },
      "source": [
        "row_number = 54\r\n",
        "data_for_prediction = val_x.iloc[row_number]  \r\n",
        "my_model.predict_proba(data_for_prediction.values.reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM2fVJCFCEtV"
      },
      "source": [
        "explainer = shap.TreeExplainer(my_model)\r\n",
        "shap_values = explainer.shap_values(data_for_prediction)\r\n",
        "shap_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnicgnOCHcd"
      },
      "source": [
        "SHAP also has nice visualisations for these values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41kQ46DKCIzl"
      },
      "source": [
        "shap.initjs()\r\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_plot.loc[val_x.index[row_number]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyh9QuaZCKWf"
      },
      "source": [
        "For non tree based models we can use the KernelExplainer to get an approximate result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxM8eQATCMQt"
      },
      "source": [
        "shap.initjs()\r\n",
        "k_explainer = shap.KernelExplainer(my_model.predict, shap.kmeans(val_x, 20))\r\n",
        "k_shap_values = k_explainer.shap_values(data_for_prediction)\r\n",
        "shap.force_plot(k_explainer.expected_value, k_shap_values, data_for_plot.loc[val_x.index[row_number]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVcG3_qqCQN9"
      },
      "source": [
        "This can also be done for multiple the rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNPueQ12IOrv"
      },
      "source": [
        "shap.initjs()\r\n",
        "explainer = shap.TreeExplainer(my_model)\r\n",
        "shap_values = explainer.shap_values(val_x.iloc[:1000])\r\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_plot.loc[val_x.index[:1000]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJRFJbPnCWRM"
      },
      "source": [
        "We can get a summary of the Shapley values as follows\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZhJeDbUCWl9"
      },
      "source": [
        "shap_values = explainer.shap_values(val_x)\r\n",
        "shap.summary_plot(shap_values[1], val_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo3KDrDKJVIW"
      },
      "source": [
        "Or for a single feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4px0MPBBfUED"
      },
      "source": [
        "shap.summary_plot(shap_values[0], val_x, plot_type='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DT2-uHDJacF"
      },
      "source": [
        "Or for the dependence between 2 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWk_334Cfo7D"
      },
      "source": [
        "shap.dependence_plot('age', shap_values[1], val_x, interaction_index='education-num', x_jitter=1, dot_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}